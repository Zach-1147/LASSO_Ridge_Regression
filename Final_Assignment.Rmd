---
title: "Final_Assignment"
author: "Leon Edmiidz, Zach Ribau"
date: "2024-02-20"
output: pdf_document
---

## HEADER

```{r}

##----------------------
### Load Libraries & Data
##-----------------------

#Define function to install libraries if not already installed on system
install_if_needed <- function(package_name) {
  if (!require(package_name, character.only = TRUE)) {
    install.packages(package_name)
    library(package_name, character.only = TRUE)
  }
}

#Create vector with required libraries
packages <- c("tidyverse","glmnet", "ggplot2","lars", "caret", "ggplot2", "GGally")

#Loop over package vector and install and load libraries
for (pkg in packages) {
  install_if_needed(pkg)
}

#load in diabetes dataset
data("diabetes")
attach(diabetes)

#Combine matrices to visualize as dataframe include row ID
full_dataset = data.frame(cbind(diabetes$x, diabetes$x2, y = diabetes$y))


##----------------------
### Data Splitting
##----------------------

#Combine X and X2 matrices, as we will train a model with all available  features.

x_combined <- cbind(x, x2)

#Set seed for reproducibility
set.seed(1545)

#Hold out 42 observations for testing
test_set_size <- 42 
test.index <- sample.int(dim(x_combined)[1], test_set_size, replace = FALSE)

#Check for standardization, even though glmnet inherently standardizes
plot(as.ts(apply(x_combined, 2, sd)), xlab="Covariate", ylab="Standard Deviation") 

#Subset training data
x_training <- x_combined[-test.index, ]
y_training <- y[-test.index]

#Subset the testing data
x_testing <- x_combined[test.index, ]
y_testing <- y[test.index]

```

```{r}
##----------------------
### Cross Validation
##----------------------

lasso1 <- cv.glmnet(x_training, y_training, type.measure="mse", nfolds=10)
plot(lasso1) 

#Look at the value corresponding to our best model, 
lambda_min <- lasso1$lambda.min

#And the conservative lse
lambda_1se <- lasso1$lambda.1se

#Now consider a set of models between these values

#We can convert our momdel coefficients accross lambda values to a dataframe
coefficients <- tidy(lasso1, exponentiate = TRUE)

#List various lambda values within the range of lambda_min to lambda_1se, summarize with the number of non zero coefficients to assess complexity. 
sps_set <- coefficients %>%
  filter(lambda >= lambda_min & lambda <= lambda_1se) %>%
  group_by(lambda) %>%
  summarize(total_nonzero = nzero) %>%
  arrange(desc(lambda))

#We see two lambda values 3.303388 and 3.625464 that are close to our best model and that have the same nzero value (18), thus we will consider the higher performing one, 3.625464.Two additional values share an nzero of 14, so we take only the 5.25992.

#Remove values corresponding to lower performing lambda values of the two pairs

sps_set <- sps_set[-c(3, 7), ]




##----------------------
### Testing 
##----------------------

#Predict response variable in testing data using our models in sps.set

prd.sps.set <- predict(lasso1, newx=x_testing,s=sps_set$lambda)
dim(prd.sps.set)

#Compute and print MSE for all of our models on the testing data,comparing to the testing response variable.

#Adapting the function shown in class
mse <- function (i,y) {
mean ( (y-i)^2 ) }	




```



#####
# Appproach for ranking covariates for PROBLEM-3 
"notes from lec" - hints
#####

```{r}


#If you standardize coefficients you can simply rank the coefficients!! But when glm reports coefficients, it has converted them from standardized forms back to original units - thus to rank them, we need to scale them again!



```
