setwd("C:/Users/zachr/Desktop/V-38/Workflow/Current Projects/BINF 6970 Assignment 2/Data & Code/6970_Assignment-2")
plot(lasso1$lambda, lasso1$cvm, type="b", log="x", xlab="Lambda", ylab="MSE")
##----------------------
### Load Libraries & Data
##-----------------------
#Define function to install libraries if not already installed on system
install_if_needed <- function(package_name) {
if (!require(package_name, character.only = TRUE)) {
install.packages(package_name)
library(package_name, character.only = TRUE)
}
}
#Create vector with required libraries
packages <- c("tidyverse","glmnet", "ggplot2","lars", "caret", "ggplot2", "GGally")
#Loop over package vector and install and load libraries
for (pkg in packages) {
install_if_needed(pkg)
}
#load in diabetes dataset
data("diabetes")
attach(diabetes)
#Combine matrices to visualize as dataframe include row ID
full_dataset = data.frame(cbind(diabetes$x, diabetes$x2, y = diabetes$y))
##----------------------
### Data Splitting
##----------------------
#Combine X and X2 matrices, as we will train a model with all available  features.
x_combined <- cbind(x, x2)
#Set seed for reproducibility
set.seed(1545)
#Hold out 42 observations for testing
test_set_size <- 42
test.index <- sample.int(dim(x_combined)[1], test_set_size, replace = FALSE)
#Check for standardization, even though glmnet inherently standardizes
plot(as.ts(apply(x_combined, 2, sd)), xlab="Covariate", ylab="Standard Deviation")
#Subset training data
x_training <- x_combined[-test.index, ]
y_training <- y[-test.index]
#Subset the testing data
x_testing <- x_combined[test.index, ]
y_testing <- y[test.index]
lasso1 <- cv.glmnet(x_training, y_training, type.measure="mse", nfolds=10)
plot(lasso1)
#Look at the value corresponding to our best model,
lambda_min <- lasso1$lambda.min
#And the conservative lse
lambda_1se <- lasso1$lambda.1se
#Now consider a set of models between these values
#We can convert our momdel coefficients accross lambda values to a dataframe
coefficients <- tidy(lasso1, exponentiate = TRUE)
packages <- c("tidyverse","glmnet","broom", "ggplot2","lars", "caret", "ggplot2", "GGally")
#Loop over package vector and install and load libraries
for (pkg in packages) {
install_if_needed(pkg)
}
coefficients <- tidy(lasso1, exponentiate = TRUE)
#List various lambda values within the range of lambda_min to lambda_1se, summarize with the number of non zero coefficients to assess complexity.
sps_set <- coefficients %>%
filter(lambda >= lambda_min & lambda <= lambda_1se) %>%
group_by(lambda) %>%
summarize(total_nonzero = nzero) %>%
arrange(desc(lambda))
plot(lasso1$lambda, lasso1$cvm, type="b", log="x", xlab="Lambda", ylab="MSE")
abline(v=lasso$lambda.min, col="red")
plot(lasso1$lambda, lasso1$cvm, type="b", log="x", xlab="Lambda", ylab="MSE")
abline(v=lasso$lambda.min, col="red")
plot(lasso1$lambda, lasso1$cvm, type="b", log="x", xlab="Lambda", ylab="MSE")
abline(v=lasso1$lambda.min, col="red")
abline(v=lasso1$lambda.1se, col="blue")
View(coefficients)
lambda_nzero_df <- data.frame(lambda = lasso1$lambda, nzero = non_zero_coefficients)
non_zero_coefficients <- lasso1$nzero
lambda_nzero_df <- data.frame(lambda = lasso1$lambda, nzero = non_zero_coefficients)
View(lambda_nzero_df)
non_zero_coefficients <- lasso1$nzero
mse_values <- lasso1$cvm
evaluation_df <- data.frame(lambda = lasso1$lambda, nzero = non_zero_coefficients)
evaluation_df <- data.frame(lambda = lasso1$lambda,
nzero = non_zero_coefficients,
mse = mse_values)
View(evaluation_df)
sps_set <- evaluation_df %>%
filter(lambda >= lambda_min & lambda <= lambda_1se) %>%
arrange(desc(lambda))
View(sps_set)
sps_set <- sps_set[-c(3, 7), ]
non_zero_coefficients <- lasso1$nzero
mse_values <- lasso1$cvm
evaluation_df <- data.frame(lambda = lasso1$lambda, nzero = non_zero_coefficients)
evaluation_df <- data.frame(lambda = lasso1$lambda,
nzero = non_zero_coefficients,
mse = mse_values)
#We can now filter this datagrame to only include our sps_set models, and comapre them accordingly.
#List various lambda values within the range of lambda_min to lambda_1se
sps_set <- evaluation_df %>%
filter(lambda >= lambda_min & lambda <= lambda_1se) %>%
arrange(desc(lambda))
# Rank the lambda values based on nzero and mse separately
evaluation_df <- evaluation_df %>%
mutate(rank_nzero = rank(nzero),  # Rank based on the number of non-zero coefficients
rank_mse = rank(mse),      # Rank based on MSE
# Combine ranks into a score, lower score is better
score = (rank_nzero + rank_mse) / 2) %>%
arrange(score)  # Arrange by score to see best lambda values first
View(evaluation_df)
#We can extract each lambda values number of non-zero coefficients, as well as mse values, and save to a dataframe
non_zero_coefficients <- lasso1$nzero
mse_values <- lasso1$cvm
evaluation_df <- data.frame(lambda = lasso1$lambda, nzero = non_zero_coefficients)
evaluation_df <- data.frame(lambda = lasso1$lambda,
nzero = non_zero_coefficients,
mse = mse_values)
#List various lambda values within the range of lambda_min to lambda_1se
sps_set <- evaluation_df %>%
filter(lambda >= lambda_min & lambda <= lambda_1se) %>%
arrange(desc(lambda))
View(sps_set)
ggplot(sps_set, aes(x = nzero, y = mse)) +
geom_point() +
geom_line() + # Optional, to connect points in order of lambda values
theme_minimal() +
labs(title = "Number of Non-Zero Coefficients vs. MSE",
x = "Number of Non-Zero Coefficients (nzero)",
y = "Mean Squared Error (mse)")
ggplot(sps_set, aes(x = nzero, y = mse)) +
geom_point() +  # Plot all points
geom_line() +   # Connect points with lines
geom_point(data = sps_set[6, ], aes(x = nzero, y = mse), color = "red", size = 4, shape = 8) + # Highlight index 6
theme_minimal() +
labs(title = "Number of Non-Zero Coefficients vs. MSE",
x = "Number of Non-Zero Coefficients (nzero)",
y = "Mean Squared Error (mse)")
coefficients_at_index_5 <- coef(lasso1, s = lambda_at_index_5)
lambda_at_index_5 <- sps_set$lambda[5]
coefficients_at_index_5 <- coef(lasso1, s = lambda_at_index_5)
View(coefficients_at_index_5)
coefficients_df <- as.data.frame(coefficients_at_index_5[coefficients_at_index_5 != 0, , drop = FALSE])
